{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11283259,"sourceType":"datasetVersion","datasetId":7054546}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T12:54:13.082263Z","iopub.execute_input":"2025-04-09T12:54:13.082571Z","iopub.status.idle":"2025-04-09T12:54:13.392752Z","shell.execute_reply.started":"2025-04-09T12:54:13.082545Z","shell.execute_reply":"2025-04-09T12:54:13.391891Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/task1-a3/shakespear_dev.txt\n/kaggle/input/task1-a3/shakespear_train.txt\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"\n# importing the modules needed for the transformer model\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\nimport numpy as np\nfrom collections import Counter\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader, TensorDataset\nimport matplotlib.pyplot as plt\n\n\n# using the GPU if available\n# otherwise using the CPU\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {DEVICE}\")\n\n# defining the maximum length of the input sequence\n# and the special tokens\nMAX_LEN = 256\nPAD_TOKEN = \"<PAD>\"\nSTOP_TOKEN = \"<STOP>\"\nUNK_TOKEN = \"<UNK>\"\nSTART_TOKEN = \"<START>\"\n\n\n\n# initialising the projections for the multi-head attention\ndef initialise_projections(d_model,d_k,d_v,n_heads):\n    return [nn.Linear(d_model,d_k*n_heads,bias=False),nn.Linear(d_model,d_k*n_heads,bias=False),nn.Linear(d_model,d_v*n_heads,bias=False)]\n\n# calculating q.k^T for the attention mechanism\n# this is the similarity score between the query and key vectors\ndef pairwise_similarities(Q,K):\n    pairwise_similarities=torch.matmul(Q,K.transpose(-2,-1))\n    return pairwise_similarities\n    \n# scaling the similarities by the square root of d_k\n# this is done to prevent the gradients from exploding\ndef attention_scaled(similarities,d_k):\n    attention_scaled=similarities/math.sqrt(d_k)\n    return attention_scaled\n \n# calculating the attention weights using softmax ; softmax(q.k^T/sqrt(d_k))\n# this is done to get the probabilities of the attention weights\ndef attention_softmax(scaled_similarities):\n    attention_softmax=F.softmax(scaled_similarities,dim=-1)\n    return attention_softmax\n   \n\n# calculating the outputs of the attention mechanism\n# this is done by multiplying the attention weights with the value vectors\n# output softmax(q.k^T/sqrt(d_k)).V\ndef compute_outputs(attention_weights,V):\n    output=torch.matmul(attention_weights,V)\n    return output\n    \n# creating a causal mask for the attention mechanism to prevent the model from looking at future tokens\n# this is done by creating a lower triangular matrix of ones and zeros\ndef make_causal_mask(seq_len):\n    mask=torch.tril(torch.ones(seq_len, seq_len)).to(DEVICE)\n    return mask\n\n\n# applying the causal mask to the similarities\ndef apply_causal_mask(similarities,mask):\n    return similarities.masked_fill(mask==0,float('-inf'))\n\n# splitting the heads for the multi-head attention mechanism\n# this is done to get the different heads for the attention mechanism\ndef split_heads(inp,n_heads):\n    batch_size,seq_len,d_model=inp.size()\n    return inp.view(batch_size,seq_len,n_heads,d_model//n_heads).transpose(1, 2)\n\n\n# merging the heads for the multi-head attention mechanism to get the final output of the multi-head attention\ndef merge_heads(heds):\n    batch_size,n_heads,seq_len,d_head=heds.size()\n    return heds.transpose(1,2).contiguous().view(batch_size,seq_len,-1)\n\n\n# splitting the heads for the query, key and value vectors\n# this is done to get the different heads for the attention mechanism\ndef split_heads_qkv(Q, K, V, n_heads):\n    q=split_heads(Q,n_heads)\n    k=split_heads(K,n_heads)\n    v=split_heads(V,n_heads)\n    return q,k,v\n    \n# calculating the attention for the multi-head attention mechanism for the query, key and value vectors\n# this is done by calculating the similarities between the query and key vectors and then applying the softmax to get the attention weights\n# and then multiplying the attention weights with the value vectors to get the final output of the multi-head attention mechanism\n# output = softmax(q.k^T/sqrt(d_k)).V\ndef self_attention(Q, K, V, mask=None):\n    # calculating the size of the query vector to get the scaling factor\n    d_k = Q.size(-1)\n    # calculating the similarities between the query and key vectors\n    # this is done by calculating q.k^T\n    similarities = pairwise_similarities(Q, K)\n    # applying scaling to the similarities by dividing by sqrt(d_k)\n    \n    scaled = attention_scaled(similarities, d_k)\n    # applying the causal mask to the similarities to prevent model from looking at future tokens\n    if mask is not None:\n        scaled = apply_causal_mask(scaled, mask)\n        # calculating the attention weights by applying softmax to the scaled similarities\n    attention = attention_softmax(scaled)\n    # calculating the outputs of the attention mechanism by multiplying the attention weights with the value vectors\n    # this is done by calculating softmax(q.k^T/sqrt(d_k)).V\n    return compute_outputs(attention, V)\n\n# defining the positional encoding for the transformer model to get the positional information of the tokens in the input sequence\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=256, dropout=0.1):\n        super().__init__()\n        max_len=int(max_len)\n        self.dropout = nn.Dropout(p=dropout)\n\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        self.register_buffer('pe', pe.unsqueeze(0))\n\n    def forward(self, x):\n        return self.dropout(x + self.pe[:, :x.size(1)])\n\n## defining the multi-head attention mechanism for the transformer model\nclass MultiHeadAttention(nn.Module):\n    # initialising the multi-head attention mechanism with the number of heads and the dropout rate\n    def __init__(self,d_model,n_heads,dropout=0.1):\n        super().__init__()\n        # defining the number of heads and the size of the key vectors\n        self.d_model=d_model\n        self.n_heads=n_heads\n        self.d_k=d_model // n_heads\n        # defining the dropout layer for the multi-head attention mechanism\n        self.dropout = nn.Dropout(dropout)\n        # defining the linear layers for the query, key and value vectors\n        self.WQ,self.WK,self.WV = initialise_projections(d_model, self.d_k, self.d_k, n_heads)\n        # defining the linear layer for the final output of the multi-head attention mechanism\n        self.fc = nn.Linear(d_model, d_model)\n\n\n# forward function for the multi-head attention mechanism, this is where the input sequence is passed through the multi-head attention mechanism\n    def forward(self, x, mask=None):\n        # calculating the batch size of the input sequence\n        batch_size = x.size(0)\n        # defining of the query, key and value vectors\n        Q = self.WQ(x)\n        K = self.WK(x)\n        V = self.WV(x)\n        \n        # splitting the heads for the query, key and value vectors to get the different heads for the attention mechanism\n        Q,K,V=split_heads_qkv(Q, K, V, self.n_heads)\n        # getting attention for the query, key and value vectors for each head.\n        attention=self_attention(Q, K, V, mask)\n        # merging the heads for the multi-head attention mechanism to get the final output of the multi-head attention mechanism\n        over_attention=merge_heads(attention)\n        # applying the linear layer for the final output of the multi-head attention mechanism\n        output=self.fc(over_attention)\n        # applying the dropout layer for the multi-head attention mechanism to prevent overfitting\n        return self.dropout(output)\n\n\n# defining the GELU activation function for the feed forward network in the transformer model to get the non-linearity in the model\nclass GELU(nn.Module):\n    def forward(self, x):\n        gas= 0.5 * (1 + torch.tanh(math.sqrt(2 / math.pi)*(x + 0.044715*torch.pow(x,3))))\n        return gas * x\n        \n# defining the transformer block for the transformer model\nclass TransformerBlock(nn.Module):\n    # initialising the transformer block with the number of heads and the dropout rate , the feed forward ratio\n    # this is the ratio of the size of the feed forward network to the size of the input sequence\n    def __init__(self,d_model,n_heads,dropout=0.1,ff_ratio=4):\n        super().__init__()\n        # attention layer for the transformer block,\n        self.attention = MultiHeadAttention(d_model, n_heads, dropout)\n        # defining the layer normalisation for the transformer block to get the normalisation of the input sequence,so that the gradients do not explode\n        # layer1 normanalisation.\n        self.norm1 = nn.LayerNorm(d_model)\n        # layer2 normalisation.\n        self.norm2 = nn.LayerNorm(d_model)\n        # defining the feed forward network for the transformer block to get the non-linearity in the model\n        self.ffn = nn.Sequential(\n            # \n            nn.Linear(d_model, ff_ratio*d_model),\n            GELU(),\n            nn.Linear(ff_ratio*d_model, d_model),\n            nn.Dropout(dropout)\n        )\n        # applying droput\n        self.dropout = nn.Dropout(dropout)\n    # forward function for the transformer block,  where the input sequence is passed through the transformer block\n    \n    def forward(self, emb, mask=None):\n        # applying normalization to input sequence (layer1 normalization)\n        norm_emb = self.norm1(emb)\n        # applying the multi-head attention mechanism to the input sequence(multihead )\n        attn_output = self.attention(norm_emb, mask)\n        # applying the dropout layer for the multi-head attention mechanism to prevent overfitting\n        emb = emb + self.dropout(attn_output)\n\n        norm_emb = self.norm2(emb)\n        # applying the feed forward network to the input sequence (feed forward network)\n        ffn_output = self.ffn(norm_emb)\n        # applying the dropout layer for the feed forward network to prevent overfitting\n        emb = emb + self.dropout(ffn_output)\n        return emb\n\n\n\n# initialising the module weighths\ndef initialize_module_weights(module):\n    \"\"\"Apply Xavier initialization to weights with more than 1 dimension.\"\"\"\n    for param in module.parameters():\n        if param.dim() > 1:\n            nn.init.xavier_normal_(param)\n# initialising the biases for the layer normalisation to zero and the weights to one\ndef initialize_layernorm(module):\n    \"\"\"Set LayerNorm bias to 0 and weight to 1.\"\"\"\n    if isinstance(module, nn.LayerNorm):\n        module.bias.data.zero_()\n        module.weight.data.fill_(1.0)\n#  initialising the weights for the transformer model using the xavier normal distribution for the weights and zero for the biases\ndef initialize_model_weights(model):\n    \"\"\"Apply both general and LayerNorm-specific initializations.\"\"\"\n    initialize_module_weights(model)\n    model.apply(initialize_layernorm)\n\n\n# defining the transformer model for the transformer model\nclass TransformerLM(nn.Module):\n    def __init__(self, vocab_size, d_model=512, n_heads=8, n_layers=6, dropout=0.1):\n        super().__init__()\n        self.d_model = d_model\n        self.n_heads=n_heads\n        self.embedding = self._build_embedding(vocab_size, d_model)\n        self.embed_scale = math.sqrt(d_model)\n        self.pos_encoder = PositionalEncoding(d_model,MAX_LEN,dropout)\n        self.layers = self._build_transformer_layers(d_model, n_heads, n_layers, dropout)\n        self.norm = nn.LayerNorm(d_model)\n        self.output_projection = lambda x: torch.matmul(x, self.embedding.weight.transpose(0, 1))\n        self.dropout = nn.Dropout(dropout)\n\n        # Apply weight initialization\n        initialize_model_weights(self)\n# building thebembedding\n    def _build_embedding(self,vocab_size,d_model):\n        return nn.Embedding(vocab_size,d_model)\n# building the transformer layers for the transformer model\n    def _build_transformer_layers(self,d_model,n_heads,n_layers,dropout):\n        return nn.ModuleList([\n            TransformerBlock(d_model, n_heads, dropout) for k in range(n_layers)\n        ])\n# forward function for the transformer model\n    def forward(self,x,mask=None):\n        # adding the embedding layer to the input sequence\n        x=self.embedding(x)*self.embed_scale\n        # adding the positional encoding to the input sequence\n        x=self.pos_encoder(x)\n# applying the causal mask to prevent model from looking at future tokens\n        if mask is None:\n            seq_len=x.size(1)\n            mask=make_causal_mask(seq_len)\n        # for each layer\n        for layer in self.layers:\n            x=layer(x, mask)\n\n        x=self.norm(x)\n        # calculating the logits for the output projection layer\n        logits=self.output_projection(x)\n        return logits, None\n\n## function to load and preprocess data.\ndef load_and_preprocess_data(train_path=\"/kaggle/input/task1-a3/shakespear_train.txt\",\n                            dev_path=\"/kaggle/input/task1-a3/shakespear_dev.txt\",\n                            test_path=\"/kaggle/input/task1-a3/shakespear_dev.txt\",\n                            min_freq=2):\n\n    def flat(tokens):\n      return [item for sublist in tokens for item in sublist]\n\n    try:#opening the files for training, validation and test data\n        with open(train_path, \"r\", encoding='utf-8') as f:\n            lines_train = [line.strip() for line in f]\n        with open(dev_path, \"r\", encoding='utf-8') as f:\n            lines_dev = [line.strip() for line in f]\n        if test_path != train_path:\n            with open(test_path, \"r\", encoding='utf-8') as f:\n                lines_test = [line.strip() for line in f]\n        else:\n            lines_test = lines_train[:100]\n    except FileNotFoundError as e:\n        print(f\"Error loading data: {e}\")\n        print(\"Using default paths may have failed. Please provide correct file paths.\")\n       \n\n    tokens_train = [line.split() for line in lines_train]\n    token_counts = Counter(flat(tokens_train))\n    # only keeeping thise words to whose count is greater or equal to  2\n    filtered_vocab = {word: count for word, count in token_counts.items() if count >= min_freq}\n# lsiting the special tokens\n    special_tokens = [PAD_TOKEN, START_TOKEN, STOP_TOKEN, UNK_TOKEN]\n    vocab = special_tokens + sorted(filtered_vocab.keys(), key=lambda w: filtered_vocab[w], reverse=True)\n\n    tokenizer = {token: i for i, token in enumerate(vocab)}\n    tokenizer_inv = {i: token for token, i in tokenizer.items()}\n    unk_id = tokenizer[UNK_TOKEN]\n\n# process line sfor input  by adding start and nd token for each input line \n    def process_lines(lines):\n        processed = []\n        for line in lines:\n            tokens = [START_TOKEN] + line.split() + [STOP_TOKEN]\n            ids = [tokenizer.get(t, unk_id) for t in tokens]\n            processed.append(ids)\n        return processed\n\n## data for testing ,rating and devlopmnet\n    data_train = process_lines(lines_train)\n    data_dev = process_lines(lines_dev)\n    data_test = process_lines(lines_test)\n\n    print(f\"sizeof the vocab: {len(vocab)}\")\n    print(f\"Training_samples: {len(data_train)}\")\n    print(f\"Validation_samples: {len(data_dev)}\")\n    print(f\"Test_samples: {len(data_test)}\")\n\n    return data_train, data_dev, data_test, tokenizer, tokenizer_inv\n\n\n\n#  function to pad the input sequenze if its length is less \ndef pad_to_length(tokens,max_len,tokenizer):\n    # checkini g if the toikens are tensor or not\n    if isinstance(tokens,torch.Tensor):\n        # if yes converting it to list\n        tokens=tokens.tolist()\n# if length pof the tokens is greater than or equal to the max length\n    if len(tokens)>=max_len:\n        # adding start and stop tokens to the input sequence\n        starting_id = tokenizer[START_TOKEN]\n        stoping_id=tokenizer[STOP_TOKEN]\n        # if the first token is start token then adding stop token to the end of the input sequence\n        if tokens[0]==starting_id:\n            paddeding=[starting_id]+tokens[1:max_len-1]+[stoping_id]\n            \n        else:\n            # if the first token is not start token then adding start token to the beginning of the input sequence\n            paddeding=tokens[:max_len]\n    else:\n        # if the length of the tokens is less than the max length then adding pad token to the input sequence\n        paddeding=tokens+[tokenizer[PAD_TOKEN]]*(max_len - len(tokens))\n\n    return paddeding[:max_len]\n\n\n# function to tokenize the input sequence by adding start and stop tokens to the input sequence\ndef tokenize(sentence, pad_to_len=None, tokenizer=None, include_stop=True):\n    tokens=sentence.split()\n    if include_stop:\n        tokens=[START_TOKEN]+tokens+[STOP_TOKEN]\n    # if unkown token is not in the tokenizer then adding pad token to the input sequence\n    # if the unknown token is in the tokenizer then adding unknown token to the input sequence\n    unkown_id=tokenizer[UNK_TOKEN] if UNK_TOKEN in tokenizer else tokenizer[PAD_TOKEN]\n    ids=[]\n    for token in tokens:\n        \n        ids.append(tokenizer.get(token, unkown_id))\n    \n    # if the pad_to_len is not None then padding the input sequence to the max length\n    if pad_to_len:\n        ids=pad_to_length(ids, pad_to_len, tokenizer)\n    return ids\n\n\n# function to decode the input sequence by removing the start and stop tokens from the input sequence\ndef decode(tokens, tokenizer_inv, end_at_stop=True, omit_pad=True, skip_special=False):\n    if isinstance(tokens, torch.Tensor):\n        tokens=tokens.tolist()\n    # if the tokens are tensor then converting it to list\n    decoded_list=[]\n    special_tokens={START_TOKEN,STOP_TOKEN,PAD_TOKEN,UNK_TOKEN}\n\n    for t in tokens:\n        token = tokenizer_inv.get(t, PAD_TOKEN)\n        if end_at_stop and token==STOP_TOKEN:\n            break\n        if omit_pad and token==PAD_TOKEN:\n            continue\n        if skip_special and token in special_tokens:\n            continue\n        decoded_list.append(token)\n        \n    return ' '.join(decoded_list)\n\n\n@torch.no_grad()\ndef evaluate_losses(data, model, tokenizer, bs=32, progress=True, pad_to_len=MAX_LEN):\n    it = range(0, len(data), bs)\n    if progress:\n        it = tqdm(it)\n\n    out = []\n    for b_start in it:\n        batch = slice(b_start, b_start + bs)\n        tokens = torch.tensor(\n            [tokenize(t, pad_to_len=pad_to_len, tokenizer=tokenizer) for t in data[batch]], dtype=torch.long\n        ).to(DEVICE)\n        X_tokens, y_tokens = tokens[:, :-1].contiguous(), tokens[:, 1:].contiguous()\n\n        model.eval()\n        logits, _ = model(X_tokens)\n        log_probs = F.log_softmax(logits, dim=-1)\n        y_log_probs = torch.gather(log_probs, 2, y_tokens[..., None])[..., 0]\n\n        for i in range(y_tokens.shape[0]):\n            not_pad = y_tokens[i] != tokenizer[\"<PAD>\"]\n            loss = -y_log_probs[i, not_pad].mean()\n            out.append(loss.item())\n\n    return out\n# generating the text using the transformer model done by passing the input sequence through the transformer model and then applying the softmax to get the probabilities of the next token\ndef generate_text(model, tokenizer, tokenizer_inv,context=\"<START>\", gen_tokens=100, temperature=0.7,top_k=40):\n    model.eval()\n    if context==\"<START>\":\n        context_tokens=[tokenizer[START_TOKEN]]\n    else:\n        context_tokens=tokenize(context,tokenizer=tokenizer,include_stop=False)\n\n    generated=context_tokens.copy()\n\n    with torch.no_grad():\n        for i in range(gen_tokens):\n            input_seq=pad_to_length(generated[-MAX_LEN:],MAX_LEN,tokenizer)\n            inputs=torch.tensor([input_seq], dtype=torch.long).to(DEVICE)\n\n            seq_len=inputs.size(1) - 1\n            mask=make_causal_mask(seq_len)\n            # passing the input sequence through the transformer model to get the logits for the next token\n            logits, k = model(inputs[:, :-1], mask)\n            #applying temperatire to the logits to get the probabilities of the next token\n            next_logits = logits[0, -1, :] / temperature\n\n            if top_k > 0:\n                indices_to_remove=next_logits<torch.topk(next_logits, top_k)[0][..., -1, None]\n                next_logits[indices_to_remove]=float('-inf')\n\n            # applying softmax to the logits to get the probabilities of the next token\n            probs = F.softmax(next_logits, dim=-1)\n            next_token = torch.multinomial(probs, num_samples=1).item()\n            # if the next token is stop token then breaking the loop\n            if next_token == tokenizer[STOP_TOKEN]:\n                break\n            generated.append(next_token)\n\n    return decode(generated, tokenizer_inv, skip_special=True)\n\n# function to plot the training and validation losses\ndef plot_losses(train_losses, val_losses):\n    plt.figure(figsize=(10, 6))\n    plt.plot(train_losses, label='Training Loss')\n    plt.plot(val_losses, label='Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Training and Validation Loss')\n    plt.legend()\n    plt.grid(True)\n    plt.savefig('training_curves.png')\n    plt.show()\n\n# def evaluate_test_set(model, test_data, tokenizer, tokenizer_inv):\n#     test_loss = evaluate_losses(test_data, model, tokenizer)\n#     perplexity = math.exp(test_loss)\n\n#     samples = []\n#     for i in range(min(5, len(test_data))):\n#         input_tokens = test_data[i]\n#         input_text = decode(input_tokens, tokenizer_inv, end_at_stop=False, omit_pad=True)\n#         generated = generate_text(model, tokenizer, tokenizer_inv, context=input_text)\n#         samples.append({\n#             'input': input_text,\n#             'generated': generated\n#         })\n\n#     return perplexity, samples\n\ndef create_data_loader(data, tokenizer, batch_size=32, shuffle=True):\n    processed_data = []\n    for seq in data:\n        if isinstance(seq, torch.Tensor):\n            seq = seq.tolist()\n        padded = pad_to_length(seq, MAX_LEN, tokenizer)\n        processed_data.append(padded)\n\n    tensor_data = torch.tensor(processed_data, dtype=torch.long)\n    dataset = TensorDataset(tensor_data)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n\ndef get_scheduler(optimizer, num_warmup_steps, num_training_steps, lr_end=1e-7):\n    def lr_lambda(currt_step):\n        if currt_step < num_warmup_steps:\n            return float(currt_step)/float(max(1, num_warmup_steps))\n        a=float(max(1, num_training_steps - num_warmup_steps))\n        progress = float(currt_step - num_warmup_steps) / a\n        return max(lr_end, 0.5 * (1.0 + math.cos(math.pi * progress)))\n\n    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n\ndef train_model(model, train_data, val_data, tokenizer, tokenizer_inv, n_epochs=25, lr=5e-4, bs=32,\n               gradient_clip=1.0, warmup_steps=2000, save_path=\"transformer_best.pth\"):\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-9, weight_decay=0.01)\n    pad_id=tokenizer[PAD_TOKEN]\n    train_losses= []\n    val_losses= []\n    best_val_loss= float('inf')\n\n    train_loader= create_data_loader(train_data, tokenizer, batch_size=bs, shuffle=True)\n    val_loader= create_data_loader(val_data, tokenizer, batch_size=bs, shuffle=False)\n\n    num_training_steps= len(train_loader)* n_epochs\n    scheduler= get_scheduler(optimizer, warmup_steps, num_training_steps)\n\n    for epoch in range(n_epochs):\n        model.train()\n        epoch_loss = []\n\n        for batch_container in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n            batch=batch_container[0].to(DEVICE)\n\n            inputs=batch[:, :-1].contiguous()\n            targets=batch[:, 1:].contiguous()\n\n            seq_len=inputs.size(1)\n            mask=make_causal_mask(seq_len)\n\n            optimizer.zero_grad()\n            logits, _ = model(inputs,mask)\n            loss = F.cross_entropy(logits.view(-1, logits.size(-1)),\n                                  targets.view(-1), ignore_index=pad_id)\n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip)\n\n            optimizer.step()\n            scheduler.step()\n            epoch_loss.append(loss.item())\n\n        train_loss = np.mean(epoch_loss)\n\n        model.eval()\n        val_losses_epoch = []\n        with torch.no_grad():\n            for batch_container in val_loader:\n                batch = batch_container[0].to(DEVICE)\n                inputs = batch[:, :-1].contiguous()\n                targets = batch[:, 1:].contiguous()\n\n                seq_len = inputs.size(1)\n                mask = make_causal_mask(seq_len)\n\n                logits, _ = model(inputs, mask)\n                loss = F.cross_entropy(logits.view(-1, logits.size(-1)),\n                                     targets.view(-1), ignore_index=pad_id)\n                val_losses_epoch.append(loss.item())\n\n        val_loss = np.mean(val_losses_epoch)\n\n        if val_loss<best_val_loss:\n            best_val_loss= val_loss\n            save_model(model,tokenizer,tokenizer_inv,save_path)\n       \n            print(f\"New best model saved with validation loss: {val_loss:.4f}\")\n\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n        \n        context=\"what are you doing in :\"\n        print(f\"Epoch {epoch+1}:\")\n        print(f\"  Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Perplexity: {math.exp(val_loss):.2f}\")\n        print(f\"  Sample: {generate_text(model, tokenizer, tokenizer_inv,context)}\")\n        print()\n\n    checkpoint = torch.load(save_path)\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n\n    return train_losses, val_losses, model\n    \ndef save_model(model, tokenizer, tokenizer_inv, path):\n    torch.save({\n        'model_state_dict': model.state_dict(),\n        'vocab_size': len(tokenizer),\n        'd_model': model.d_model,\n        'n_heads': model.n_heads,\n        'n_layers': len(model.layers),\n        'dropout': model.dropout.p,\n        'tokenizer': tokenizer,\n        'tokenizer_inv': tokenizer_inv\n    }, path)\n    \ndef main():\n    train_data, val_data, test_data, tokenizer, tokenizer_inv = load_and_preprocess_data(\n        train_path=\"/kaggle/input/task1-a3/shakespear_train.txt\",\n        dev_path=\"/kaggle/input/task1-a3/shakespear_dev.txt\",\n        test_path=\"/kaggle/input/task1-a3/shakespear_dev.txt\",\n        min_freq=2\n    )\n\n    model=TransformerLM(\n        vocab_size=len(tokenizer),\n        d_model=256,\n        n_heads=4,\n        n_layers=4,\n        dropout=0.2\n    ).to(DEVICE)\n\n    print(\"Model Summary:\")\n    print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n\n    train_losses, val_losses, model = train_model(\n        model, train_data, val_data, tokenizer, tokenizer_inv,\n        n_epochs=15,\n        lr=5e-4,\n        bs=32,\n        gradient_clip=1.0,\n        warmup_steps=2000,\n        save_path=\"transformer1_shakespeare_best.pth\"\n    )\n\n    plot_losses(train_losses, val_losses)\n    \n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T12:54:13.403899Z","iopub.execute_input":"2025-04-09T12:54:13.404178Z","iopub.status.idle":"2025-04-09T13:00:25.433177Z","shell.execute_reply.started":"2025-04-09T12:54:13.404151Z","shell.execute_reply":"2025-04-09T13:00:25.432481Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nsizeof the vocab: 6395\nTraining_samples: 9837\nValidation_samples: 1304\nTest_samples: 1304\nModel Summary:\nParameters: 4,793,600\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 308/308 [00:23<00:00, 12.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved with validation loss: 5.9811\nEpoch 1:\n  Train Loss: 7.7242, Val Loss: 5.9811, Perplexity: 395.86\n  Sample: what are you doing in :\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 308/308 [00:22<00:00, 13.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved with validation loss: 5.2651\nEpoch 2:\n  Train Loss: 5.8716, Val Loss: 5.2651, Perplexity: 193.47\n  Sample: what are you doing in : , to . : . : : , , : , . . , to . you . , , , , . of , : : , : . ? , . , in : . ? 's . . . , , . : than . : : :\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 308/308 [00:22<00:00, 13.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved with validation loss: 4.9588\nEpoch 3:\n  Train Loss: 5.3990, Val Loss: 4.9588, Perplexity: 142.42\n  Sample: what are you doing in : : and of and ! , , , 's from : to , , : than 's . : , , of as with ; and to of and ; 'd ; to of of him ' , , to , for : , and to , : . , : of on ! of ; : of , and , , , I , of ; and and , of and to To that ; , , ! and , : and of to and . . of : The , of , of , '\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 308/308 [00:22<00:00, 13.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved with validation loss: 4.7773\nEpoch 4:\n  Train Loss: 5.1450, Val Loss: 4.7773, Perplexity: 118.78\n  Sample: what are you doing in : , and of By , and and To to to and And For , , 'd and And to , And And of , : and and and ; ; of , and and , and . : , 'd and of and and and of : of ; of to , , . and to of of than of of of than of , 'd , , , 'd or and . , and of and of and , and and 'd of 'd . to , , that : and than , And 'd\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 308/308 [00:22<00:00, 13.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved with validation loss: 4.6448\nEpoch 5:\n  Train Loss: 4.9579, Val Loss: 4.6448, Perplexity: 104.04\n  Sample: what are you doing in : it and it Is and to of And 'd 'd of 'd , 'd And ! and of and and ' to ' and on of , of by 'd or me And , 'd of And and 'd 'd . 'd , 'd . 'd ' , For Of 'd of ' 'd To To for and on And 'd 'd and And And of And And 'd , up , ; , ' n't and of 'd of 'd 'd or by of ' and To of of Of For and upon and and ' of\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 308/308 [00:22<00:00, 13.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved with validation loss: 4.5767\nEpoch 6:\n  Train Loss: 4.8205, Val Loss: 4.5767, Perplexity: 97.20\n  Sample: what are you doing in : For ' ' ' That ' n't ' ' ' n't '\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 308/308 [00:22<00:00, 13.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved with validation loss: 4.5139\nEpoch 7:\n  Train Loss: 4.7121, Val Loss: 4.5139, Perplexity: 91.28\n  Sample: what are you doing in : GLOUCESTER That KING n't 'd ' and At '\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 308/308 [00:22<00:00, 13.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved with validation loss: 4.4855\nEpoch 8:\n  Train Loss: 4.6100, Val Loss: 4.4855, Perplexity: 88.72\n  Sample: what are you doing in : KING or And This KING KING 'd 'd 'd KING KING KING RICHARD , RICHARD o 'd with but 'd up for on for up And KING 'd where The KING for 'd and for and 'd KING KING and 'd , Of and 'd of And where of With 'd on for 'd For For RICHARD 'd And , RICHARD 'd In of the or with KING 'd away of 'd and in , for on EDWARD of For in 'd . up 'd by , of KING of KING and\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 308/308 [00:22<00:00, 13.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved with validation loss: 4.4447\nEpoch 9:\n  Train Loss: 4.5155, Val Loss: 4.4447, Perplexity: 85.17\n  Sample: what are you doing in : 'd and and away KING GLOUCESTER and and and away GLOUCESTER 'd And 'd 'd 'd is To In ? ' and With KING and and ? ? of 'd What is KING and for and and 'd And or 'd ' 'd or KING 'd 'd and 'd for GLOUCESTER on for ' First by away 'd and at ? 'd and and of KING and ? of ' 'd 'd 'd KING For and and and and 'd 'd And KING at SICINIUS to\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 308/308 [00:22<00:00, 13.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved with validation loss: 4.4201\nEpoch 10:\n  Train Loss: 4.4270, Val Loss: 4.4201, Perplexity: 83.10\n  Sample: what are you doing in : and And What And The but The KING o o o and And away First and But and and What And and In I . away RICHARD and To and and And ' o I KING And SICINIUS in RICHARD ? And and And KING And and and And for and And The and KING ? SICINIUS and and and ' of away To for and with 'd and ' And and and o . and and and for o RICHARD and To ? and on is are is ; with ; And for RICHARD\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|██████████| 308/308 [00:22<00:00, 13.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11:\n  Train Loss: 4.3485, Val Loss: 4.4242, Perplexity: 83.45\n  Sample: what are you doing in : KING For o But to And for away and KING . and and HENRY and That To in To for for and EDWARD for But and KING for To And KING in To RICHARD And For . or ? in . o SICINIUS and Second ? SICINIUS ? . and RICHARD for RICHARD away away GLOUCESTER at of and . RICHARD RICHARD and and o And for HENRY . . To and or and ? EDWARD at for . . or for , is is EDWARD RICHARD RICHARD is and and . KING of\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12: 100%|██████████| 308/308 [00:22<00:00, 13.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12:\n  Train Loss: 4.2816, Val Loss: 4.4226, Perplexity: 83.31\n  Sample: what are you doing in : And and and In for for EDWARD KING KING First SICINIUS and What and for for For And and KING Is and and RICHARD 'd for of away KING And RICHARD of ? of and for HENRY and and In To . of and for and and First and GLOUCESTER for 'd and of to of ? of with RICHARD away 'd and to to With And for KING or and With and With KING What That and o KING of . RICHARD and RICHARD to for 'd of of HENRY\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13: 100%|██████████| 308/308 [00:22<00:00, 13.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved with validation loss: 4.4180\nEpoch 13:\n  Train Loss: 4.2246, Val Loss: 4.4180, Perplexity: 82.93\n  Sample: what are you doing in : A And and 'd KING to and for SICINIUS for And That KING on for of And here and SICINIUS for away o away and for at KING 'd and HENRY at KING Is First for for and What for In and and and and for and or for And First And and for of of and and o 'd And and and 'd for SICINIUS What or First and o and is But and and is Second and and SICINIUS And to And and where And KING and where and\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14: 100%|██████████| 308/308 [00:22<00:00, 13.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14:\n  Train Loss: 4.1899, Val Loss: 4.4188, Perplexity: 83.00\n  Sample: what are you doing in : and And With 'd And KING . and KING KING And and . and and and RICHARD RICHARD and And RICHARD is 'd and and and for and to And for where KING or 'd to and and 'd and and for away That First KING and and And . where at for and for . 'd and with 'd Of and for away to and of for 'd KING and 'd and Of SICINIUS Of and KING and here and with First HENRY and and of KING KING . and for Of A of\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15: 100%|██████████| 308/308 [00:22<00:00, 13.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15:\n  Train Loss: 4.1729, Val Loss: 4.4202, Perplexity: 83.11\n  Sample: what are you doing in : Is DUKE What KING for for and and KING for for and o o where at ? RICHARD and and and and of KING 'd ? And and 'd With and for First at And And of and and And at And And and 'd With First on and and 'd and In and away to for KING KING KING here and of and o To What and to For The KING for and and In ? and and for at and . And for of And away in and for and And KING\n\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-8-9658cc182c85>:634: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(save_path)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"import os\n\ndef inference(model_path, test_file, temperature=0.6):\n    \"\"\"Load model and generate text from test file prompts with proper evaluation.\"\"\"\n    \n    # Load the saved model checkpoint\n    checkpoint = torch.load(model_path, map_location=DEVICE)  # Removed weights_only=True\n\n    # Initialize model with saved hyperparameters\n    model = TransformerLM(\n        vocab_size=checkpoint['vocab_size'],\n        d_model=checkpoint['d_model'],\n        n_heads=checkpoint['n_heads'],\n        n_layers=checkpoint['n_layers'],\n        dropout=checkpoint['dropout']\n    ).to(DEVICE)\n\n    # Load model weights\n    model.load_state_dict(checkpoint['model_state_dict'])\n\n    # Read and process the input from test file\n    with open(test_file, \"r\", encoding=\"utf-8\") as f:\n        test_lines = [line.strip() for line in f if line.strip()]  # Skip empty lines\n\n    # No need to tokenize here — pass raw text lines directly\n    test_data = test_lines\n\n    # Calculate test loss using evaluate_losses\n    test_losses = evaluate_losses(\n        test_data, \n        model, \n        checkpoint['tokenizer'],\n        bs=32,\n        progress=True\n    )\n\n    # Calculate average perplexity\n    avg_test_loss = np.mean(test_losses)\n    perplexity = math.exp(avg_test_loss)\n\n    # Generate text for each prompt in test file\n    generated_texts = []\n    for line in test_lines[:5]:  # Generate for first 5 lines as example\n        generated_text = generate_text(\n            model=model,\n            tokenizer=checkpoint['tokenizer'],\n            tokenizer_inv=checkpoint['tokenizer_inv'],\n            context=line,\n            gen_tokens=50,\n            temperature=temperature\n        )\n        generated_texts.append(generated_text)\n\n    return generated_texts, perplexity\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T13:00:25.438918Z","iopub.execute_input":"2025-04-09T13:00:25.439107Z","iopub.status.idle":"2025-04-09T13:00:25.457698Z","shell.execute_reply.started":"2025-04-09T13:00:25.439089Z","shell.execute_reply":"2025-04-09T13:00:25.457017Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"if os.path.exists(\"/kaggle/working/transformer1_shakespeare_best.pth\"):\n    generated_texts, ppl = inference(\n        \"/kaggle/working/transformer1_shakespeare_best.pth\", \n        \"/kaggle/input/task1-a3/shakespear_dev.txt\"\n    )\n    print(f\"\\nFinal Perplexity on test set: {ppl:.4f}\")\n    print(\"\\nGenerated text samples:\")\n    for i, text in enumerate(generated_texts):\n        print(f\"\\nSample {i+1}:\\n{text}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T13:00:25.458440Z","iopub.execute_input":"2025-04-09T13:00:25.458709Z","iopub.status.idle":"2025-04-09T13:00:27.745481Z","shell.execute_reply.started":"2025-04-09T13:00:25.458688Z","shell.execute_reply":"2025-04-09T13:00:27.744686Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-10-8eaf2222740a>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(model_path, map_location=DEVICE)  # Removed weights_only=True\n100%|██████████| 41/41 [00:01<00:00, 32.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nFinal Perplexity on test set: 62.3472\n\nGenerated text samples:\n\nSample 1:\n, if there be no remedy for it , but that you will needs buy and sell men and women like beasts , we shall have all the world drink and white bastard . Of and And and And and and And and and BRUTUS and and and 'd and and for In and and or And A to and And and and And and First and and and or away for With And and What and SICINIUS And and and and First and\n\nSample 2:\nDUKE VINCENTIO : O heavens ! KING KING Second and and and for . for KING KING away A and . and and for for for and And and to KING ; 'd for for and and for on and away and and for of And and and o\n\nSample 3:\nwhat stuff is here POMPEY : 'T was never merry world since , of two , the was put down , and the worser by order of law a gown to keep him warm ; and with and too , to signify , that craft , being than innocency , stands for the . and and and 'd for and and and for KING and and and And for and First and and And and and and away and and and and and and o on 'd To and And First and and and , and That and The and\n\nSample 4:\nELBOW : Come your way , sir . for and to and ; for for for 'd and and For 'd for What and and for What away KING and for and and for away and 'd with are are for and for for of . and of for First\n\nSample 5:\nyou , good father friar . away and and and away . and And of o are And KING of in With First and That and for And With and at to and and and away and and KING KING RICHARD and And of And and away and\n","output_type":"stream"}],"execution_count":11}]}